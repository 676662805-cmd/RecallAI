import speech_recognition as sr
import os
import sys
import io
import re
import requests
from dotenv import load_dotenv

# å…¨å±€ state å¼•ç”¨ï¼ˆä¸ matcher.py ç›¸åŒçš„æœºåˆ¶ï¼‰
_global_state = None

def set_audio_global_state(state):
    """ä» main.py è®¾ç½®å…¨å±€ state å¼•ç”¨"""
    global _global_state
    _global_state = state

def get_base_path():
    """è·å–ç¨‹åºè¿è¡Œçš„åŸºç¡€è·¯å¾„ï¼Œæ”¯æŒå¼€å‘å’Œæ‰“åŒ…ç¯å¢ƒ"""
    if getattr(sys, 'frozen', False):
        # æ‰“åŒ…åçš„ exe è¿è¡Œæ—¶
        return os.path.dirname(sys.executable)
    else:
        # å¼€å‘ç¯å¢ƒ
        return os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# åŠ è½½ .env æ–‡ä»¶ï¼ˆæ”¯æŒæ‰“åŒ…åçš„è·¯å¾„ï¼‰
env_path = os.path.join(get_base_path(), '.env')
if os.path.exists(env_path):
    load_dotenv(env_path)
    print(f"âœ… Loaded .env from: {env_path}")
else:
    load_dotenv()  # å°è¯•ä»é»˜è®¤ä½ç½®åŠ è½½
    print(f"âš ï¸ .env not found at {env_path}, using default")

# è·å– Render äº‘ç«¯ URL
RENDER_URL = os.getenv("RENDER_URL", "https://recallai-d9sc.onrender.com")

class AudioService:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        
        # --- ä½ çš„ç¨³å¥è®¾ç½® ---
        self.recognizer.pause_threshold = 0.8
        self.recognizer.energy_threshold = 300 
        self.recognizer.dynamic_energy_threshold = True 
        
        # --- âœ¨ æ–°å¢ï¼šåˆå§‹åŒ–æ—¶è‡ªåŠ¨æŸ¥æ‰¾è®¾å¤‡ ---
        self.target_device_index = self._find_device_index()
        
        # --- ğŸŒ äº‘ç«¯åŒ–ï¼šç”¨æˆ· Token (éœ€è¦ä»å¤–éƒ¨è®¾ç½®) ---
        self.user_token = None
    
    def set_token(self, token: str):
        """è®¾ç½®ç”¨æˆ· Tokenï¼Œç”¨äºäº‘ç«¯ API é‰´æƒ"""
        self.user_token = token
    
    def reload_device(self):
        """é‡æ–°è¯»å–è®¾å¤‡é…ç½®ï¼ˆç”¨äºåˆ‡æ¢éº¦å…‹é£/CABLEï¼‰"""
        print("ğŸ”„ Reloading audio device configuration...")
        self.target_device_index = self._find_device_index()
        device_status = f"Index {self.target_device_index}" if self.target_device_index is not None else "Default Mic"
        print(f"âœ… Audio device updated to: [{device_status}]")
        
    def _find_device_index(self):
        """
        æ ¹æ® .env ä¸­çš„ MIC_DEVICE_NAME æŸ¥æ‰¾è®¾å¤‡ç´¢å¼•
        """
        target_name = os.getenv("MIC_DEVICE_NAME", "Default")
        
        # å¦‚æœé…ç½®æ˜¯ Default æˆ–ç©ºï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤
        if not target_name or target_name.lower() == "default":
            print("ğŸ§ Using Default Microphone (System Default)")
            return None
            
        print(f"ğŸ” Searching for audio device containing: '{target_name}'...")
        
        # éå†è®¾å¤‡åˆ—è¡¨è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        try:
            mics = sr.Microphone.list_microphone_names()
            for i, name in enumerate(mics):
                if target_name.lower() in name.lower():
                    print(f"âœ… Found Target Device: [Index {i}] {name}")
                    return i
        except Exception as e:
            print(f"âš ï¸ Error listing microphones: {e}")

        print(f"âš ï¸ Device '{target_name}' not found! Falling back to Default Mic.")
        return None

    def listen_and_transcribe(self):
        # æ˜¾ç¤ºå½“å‰æ­£åœ¨ç›‘å¬å“ªä¸ªè®¾å¤‡ï¼Œæ–¹ä¾¿è°ƒè¯•
        device_status = f"Index {self.target_device_index}" if self.target_device_index is not None else "Default Mic"
        print(f"ğŸ¤ Listening on [{device_status}]... (Using Groq Turbo)")
        
        try:
            # å…³é”®ä¿®æ”¹ï¼šä¼ å…¥ device_index
            with sr.Microphone(device_index=self.target_device_index) as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                # å½•éŸ³å‚æ•°
                audio_data = self.recognizer.listen(source, timeout=5, phrase_time_limit=20)
                print("â³ Transcribing...")

            wav_bytes = audio_data.get_wav_data()
            audio_file = io.BytesIO(wav_bytes)
            audio_file.name = "audio.wav" 

            # ğŸŒ ä½¿ç”¨äº‘ç«¯ API (Render) è¿›è¡Œè½¬å½•
            if not self.user_token:
                print("âŒ No user token set! Please call set_token() first")
                return None
            
            try:
                import time
                start_time = time.time()
                
                # å‡†å¤‡æ–‡ä»¶å’Œè¯·æ±‚å¤´
                files = {'file': ('audio.wav', audio_file, 'audio/wav')}
                headers = {'Authorization': f'Bearer {self.user_token}'}
                
                print(f"ğŸ“¤ Sending audio to cloud API ({RENDER_URL})...")
                
                # å‘é€è¯·æ±‚åˆ° Render äº‘ç«¯ (å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’ï¼Œé€‚åº”å›½é™…ç½‘ç»œå»¶è¿Ÿ)
                response = requests.post(
                    f"{RENDER_URL}/v1/proxy/transcribe",
                    files=files,
                    headers=headers,
                    timeout=60  # âœ¨ å¢åŠ åˆ°60ç§’ï¼Œé€‚åº”ä¸­å›½ç­‰åœ°åŒºçš„ç½‘ç»œå»¶è¿Ÿ
                )
                
                elapsed = time.time() - start_time
                print(f"â±ï¸ Cloud API response time: {elapsed:.2f}s")
                
                if response.status_code != 200:
                    if _global_state is not None:
                        _global_state.cloud_api_error = {"status": response.status_code, "message": response.text}
                    return None
                
                result = response.json()
                text = result.get("text", "").strip()
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ Request Error: {e}")
                return None
            except Exception as e:
                print(f"âŒ Unexpected Error: {e}")
                return None

            # --- å¢å¼ºçš„åƒåœ¾è¯è¿‡æ»¤ ---
            # 1. å®Œå…¨åŒ¹é…è¿‡æ»¤ï¼ˆå¿½ç•¥å¤§å°å†™å’Œæ ‡ç‚¹ï¼‰
            hallucinations = [
                "thank you", "thanks", "you", "yeah", "yes", "okay", "ok", 
                "um", "uh", "hmm", "mhm", "ah", "oh", "well"
            ]
            
            # æ¸…ç†åçš„æ–‡æœ¬ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
            text_clean = re.sub(r'[^\w\s]', '', text.lower())
            
            # 2. å¦‚æœæ•´å¥è¯å°±æ˜¯åƒåœ¾è¯
            if text_clean in hallucinations:
                print(f"ğŸ‘» Filtered Hallucination (exact): '{text}'")
                return None
            
            # 3. å¦‚æœå¥å­å¾ˆçŸ­ï¼ˆ<8ä¸ªå­—ç¬¦ï¼‰ä¸”åŒ…å«thank/youç­‰å…³é”®è¯
            if len(text) < 8 and any(word in text_clean for word in ["thank", "you", "thanks"]):
                print(f"ğŸ‘» Filtered Hallucination (short): '{text}'")
                return None
            
            # 4. å¦‚æœåªæœ‰1-2ä¸ªå•è¯ä¸”æ˜¯å¸¸è§ç¤¼è²Œç”¨è¯­
            words = text_clean.split()
            if len(words) <= 2 and all(w in hallucinations for w in words):
                print(f"ğŸ‘» Filtered Hallucination (polite): '{text}'")
                return None

            print(f"ğŸ—£ï¸ You said: {text}")
            return text

        except sr.WaitTimeoutError:
            return None
        except Exception as e:
            print(f"âŒ Audio Error: {e}")
            return None