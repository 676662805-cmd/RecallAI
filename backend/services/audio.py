import speech_recognition as sr
import os
import io
import re
from groq import Groq
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("GROQ_API_KEY")
if not api_key:
    print("âš ï¸ GROQ_API_KEY not set in environment. AI features will be disabled.")
    client = None
else:
    client = Groq(api_key=api_key)

class AudioService:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        
        # --- ä½ çš„ç¨³å¥è®¾ç½® ---
        self.recognizer.pause_threshold = 0.8
        self.recognizer.energy_threshold = 300 
        self.recognizer.dynamic_energy_threshold = True 
        
        # --- âœ¨ æ–°å¢ï¼šåˆå§‹åŒ–æ—¶è‡ªåŠ¨æŸ¥æ‰¾è®¾å¤‡ ---
        self.target_device_index = self._find_device_index()
        
    def _find_device_index(self):
        """
        æ ¹æ® .env ä¸­çš„ MIC_DEVICE_NAME æŸ¥æ‰¾è®¾å¤‡ç´¢å¼•
        """
        target_name = os.getenv("MIC_DEVICE_NAME", "Default")
        
        # å¦‚æœé…ç½®æ˜¯ Default æˆ–ç©ºï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤
        if not target_name or target_name.lower() == "default":
            print("ğŸ§ Using Default Microphone (System Default)")
            return None
            
        print(f"ğŸ” Searching for audio device containing: '{target_name}'...")
        
        # éå†è®¾å¤‡åˆ—è¡¨è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        try:
            mics = sr.Microphone.list_microphone_names()
            for i, name in enumerate(mics):
                if target_name.lower() in name.lower():
                    print(f"âœ… Found Target Device: [Index {i}] {name}")
                    return i
        except Exception as e:
            print(f"âš ï¸ Error listing microphones: {e}")

        print(f"âš ï¸ Device '{target_name}' not found! Falling back to Default Mic.")
        return None

    def listen_and_transcribe(self):
        # æ˜¾ç¤ºå½“å‰æ­£åœ¨ç›‘å¬å“ªä¸ªè®¾å¤‡ï¼Œæ–¹ä¾¿è°ƒè¯•
        device_status = f"Index {self.target_device_index}" if self.target_device_index is not None else "Default Mic"
        print(f"ğŸ¤ Listening on [{device_status}]... (Using Groq Turbo)")
        
        try:
            # å…³é”®ä¿®æ”¹ï¼šä¼ å…¥ device_index
            with sr.Microphone(device_index=self.target_device_index) as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                # å½•éŸ³å‚æ•°
                audio_data = self.recognizer.listen(source, timeout=5, phrase_time_limit=20)
                print("â³ Transcribing...")

            wav_bytes = audio_data.get_wav_data()
            audio_file = io.BytesIO(wav_bytes)
            audio_file.name = "audio.wav" 

            # ä½¿ç”¨ Turbo æ¨¡å‹ + å¼ºåˆ¶è‹±æ–‡
            if client is None:
                print("âš ï¸ Groq client not available, cannot transcribe")
                return None
                
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3-turbo", 
                file=audio_file,
                response_format="json",
                language="en" 
            )
            
            text = transcript.text.strip()

            # --- å¢å¼ºçš„åƒåœ¾è¯è¿‡æ»¤ ---
            # 1. å®Œå…¨åŒ¹é…è¿‡æ»¤ï¼ˆå¿½ç•¥å¤§å°å†™å’Œæ ‡ç‚¹ï¼‰
            hallucinations = [
                "thank you", "thanks", "you", "yeah", "yes", "okay", "ok", 
                "um", "uh", "hmm", "mhm", "ah", "oh", "well"
            ]
            
            # æ¸…ç†åçš„æ–‡æœ¬ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
            text_clean = re.sub(r'[^\w\s]', '', text.lower())
            
            # 2. å¦‚æœæ•´å¥è¯å°±æ˜¯åƒåœ¾è¯
            if text_clean in hallucinations:
                print(f"ğŸ‘» Filtered Hallucination (exact): '{text}'")
                return None
            
            # 3. å¦‚æœå¥å­å¾ˆçŸ­ï¼ˆ<8ä¸ªå­—ç¬¦ï¼‰ä¸”åŒ…å«thank/youç­‰å…³é”®è¯
            if len(text) < 8 and any(word in text_clean for word in ["thank", "you", "thanks"]):
                print(f"ğŸ‘» Filtered Hallucination (short): '{text}'")
                return None
            
            # 4. å¦‚æœåªæœ‰1-2ä¸ªå•è¯ä¸”æ˜¯å¸¸è§ç¤¼è²Œç”¨è¯­
            words = text_clean.split()
            if len(words) <= 2 and all(w in hallucinations for w in words):
                print(f"ğŸ‘» Filtered Hallucination (polite): '{text}'")
                return None

            print(f"ğŸ—£ï¸ You said: {text}")
            return text

        except sr.WaitTimeoutError:
            return None
        except Exception as e:
            print(f"âŒ Audio Error: {e}")
            return None