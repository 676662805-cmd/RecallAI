import speech_recognition as sr
import os
import io
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class AudioService:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        
        # --- å›æ»šå…³é”®ç‚¹ ---
        # è°ƒå› 0.8 æˆ– 1.0ã€‚è¿™æ˜¯æœ€ç¨³çš„æ•°å€¼ã€‚
        # æ„å‘³ç€ï¼šç”¨æˆ·è¯´å®Œè¯åï¼Œå¿…é¡»åœé¡¿ 0.8ç§’ï¼Œç³»ç»Ÿæ‰è®¤ä¸ºâ€œè¿™å¥è¯´å®Œäº†â€ã€‚
        # è™½ç„¶æ…¢ä¸€ç‚¹ï¼Œä½†ç»å¯¹ä¸ä¼šåˆ‡æ–­ä½ çš„è¯ã€‚
        self.recognizer.pause_threshold = 0.8
        
        self.recognizer.energy_threshold = 300 
        self.recognizer.dynamic_energy_threshold = True # å¼€å¯åŠ¨æ€è°ƒæ•´
        
    def listen_and_transcribe(self):
        print("ğŸ¤ Listening... (Speak normally)")
        
        try:
            with sr.Microphone() as source:
                # ç¨å¾®ç»™ä¸€ç‚¹æ—¶é—´é€‚åº”åº•å™ªï¼Œé˜²è¯¯è§¦
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                
                # è¿™é‡Œçš„ timeout æ˜¯æŒ‡â€œå¦‚æœå‡ ç§’æ²¡äººè¯´è¯å°±é€€å‡ºâ€ï¼Œphrase_time_limit æ˜¯â€œå•å¥æœ€é•¿å½•å¤šä¹…â€
                audio_data = self.recognizer.listen(source, timeout=5, phrase_time_limit=20)
                print("â³ Transcribing...")

            # å†…å­˜ç›´ä¼  (ä¿ç•™è¿™ä¸ªä¼˜åŒ–ï¼Œå› ä¸ºå®ƒä¸å½±å“å‡†ç¡®ç‡ï¼Œåªæé€Ÿ)
            wav_bytes = audio_data.get_wav_data()
            audio_file = io.BytesIO(wav_bytes)
            audio_file.name = "audio.wav" 

            # å¼ºåˆ¶è‹±æ–‡ (ä¿ç•™è¿™ä¸ªä¼˜åŒ–ï¼Œè§£å†³éŸ©è¯­é—®é¢˜)
            transcript = client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file,
                language="en" 
            )
            
            text = transcript.text
            print(f"ğŸ—£ï¸ You said: {text}")
            return text

        except sr.WaitTimeoutError:
            return None
        except Exception as e:
            print(f"âŒ Audio Error: {e}")
            return None