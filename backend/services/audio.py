import speech_recognition as sr
import os
import io
from groq import Groq
from dotenv import load_dotenv

load_dotenv()
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

class AudioService:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        
        # ç¨³å¥è®¾ç½®
        self.recognizer.pause_threshold = 0.8
        self.recognizer.energy_threshold = 300 
        self.recognizer.dynamic_energy_threshold = True 
        
    def listen_and_transcribe(self):
        print("ğŸ¤ Listening... (Using Groq Turbo)")
        
        try:
            with sr.Microphone() as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                # å½•éŸ³å‚æ•°
                audio_data = self.recognizer.listen(source, timeout=5, phrase_time_limit=20)
                print("â³ Transcribing...")

            wav_bytes = audio_data.get_wav_data()
            audio_file = io.BytesIO(wav_bytes)
            audio_file.name = "audio.wav" 

            # --- å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ Turbo æ¨¡å‹ ---
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3-turbo",  # <--- å·²æ›´æ–°ä¸ºæœ€æ–°å¯ç”¨æ¨¡å‹
                file=audio_file,
                response_format="json",
                language="en" # ä¾ç„¶å¼ºåˆ¶è‹±æ–‡ï¼Œé˜²æ­¢å¹»è§‰
            )
            
            text = transcript.text
            print(f"ğŸ—£ï¸ You said: {text}")
            return text

        except sr.WaitTimeoutError:
            return None
        except Exception as e:
            print(f"âŒ Audio Error: {e}")
            return None